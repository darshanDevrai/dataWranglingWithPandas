{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I face many challenges while completing this project. Following are the challenges faced by me during this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from csv file and getting image prediction data generated by Neural network from the udacity's server was easy. But I was getting an error while creating twitter application to get the api key. So  I contacted to David Venturi and he gave me the data file through email. After that getting required useful information was not that hard and I gathered all the useful data successfully. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly I was not sure how to approach this data assessing step. I had no idea what to do. I decided to do visual assessing first by printing head() of the dataframe. Then I saw some issues in the data. So after that I started doing visual and programming assessing simultaniously. I found various quality as well as tidiness issues like there were retweets, unnecessary columns, required to combine two or more columns into one and so on. While assessing I realized that most of the variables in the data are extracted from the tweet text. So at outset I was clueless about the assessing but eventually I found some issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this was the toughest step of all of three. After finding issues I started tackling one issue at a time. Most of the quality issues were not that hard to resolve. As mentioned earlier, the tweet text were very important as other variables are extracted from it. So after reading some tweet texts I thought I can extract the gender of the dog. So I came across string matching. I spent a lot of time iterating over all the rows in dataframe, get tweet text out of them and extract gender by matching some words in the tweet text. For example if tweet text contains the word \"He\" then the gender is male. Similarly if tweet text contains the word \"She\" then the gender is female. During this process I did make a programming structre with the use of functions to iterate through whole dataframe. I used that structure for later data extraction from the tweet text. But while extracting the correct ratings from the text I had to use Regular Expression. I am familier with RegEx but usually I used them once or twice in my college projects for username and email validation. But here I had to match a different string so it took me a lot of time to get the correct regular expression to extract the rating (I have searched and used various websites for this. I will provide the link for such websites below). I spent most of my time during this step. Later, I used the same structure of iteration and function on the image prediction data to define the breed of the dog. I took the breed with highest confidence as a final breed of the dog which makes sense. After doing all the data cleansing process I had to combine the three dataframes using the inner joins of pandas and drop the unnecessary columns. Then I saved the cleaned data in the twitter_archive_master.csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning was the most challenging part but I really enjoyed all the three steps of data wrangling. But the most interesting part was the data analyzing after the data wrangling process. To get the useful insights from the data we have cleaned is the amazing feeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links of the websites used during this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read ison from text -\n",
    "https://stackoverflow.com/questions/47889565/reading-json-objects-from-text-file-into-pandas\n",
    "\n",
    "To create a column with loop - \n",
    "https://chrisalbon.com/python/data_wrangling/pandas_create_column_with_loop/\n",
    "\n",
    "Gender finding - \n",
    "https://developmentality.wordpress.com/2011/09/22/python-gotcha-word-boundaries-in-regular-expressions/\n",
    "\n",
    "Display full width-\n",
    "https://stackoverflow.com/questions/25351968/how-to-display-full-non-truncated-dataframe-information-in-html-when-convertin\n",
    "\n",
    "Reg ex -\n",
    "https://stackoverflow.com/questions/24113162/regexp-to-match-fraction\n",
    "([1-9]\\.?[0-9]*)\\/(10)\n",
    "\n",
    "Combine dis - \n",
    "https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "\n",
    "\n",
    "Save df to csv -\n",
    "https://stackoverflow.com/questions/16923281/pandas-writing-dataframe-to-csv-file\n",
    "\n",
    "Cor and ggpzirs\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization-scatter-matrix\n",
    "\n",
    " \n",
    "Stackoverflow for some other minor issues.\n",
    "\n",
    "pandas documentation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
